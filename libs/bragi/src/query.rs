// Copyright Â© 2016, Canal TP and/or its affiliates. All rights reserved.
//
// This file is part of Navitia,
//     the software to build cool stuff with public transport.
//
// Hope you'll enjoy and contribute to this project,
//     powered by Canal TP (www.canaltp.fr).
// Help us simplify mobility and open public transport:
//     a non ending quest to the responsive locomotion way of traveling!
//
// LICENCE: This program is free software; you can redistribute it
// and/or modify it under the terms of the GNU Affero General Public
// License as published by the Free Software Foundation, either
// version 3 of the License, or (at your option) any later version.
//
// This program is distributed in the hope that it will be useful, but
// WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
// Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public
// License along with this program. If not, see
// <http://www.gnu.org/licenses/>.
//
// Stay tuned using
// twitter @navitia
// IRC #navitia on freenode
// https://groups.google.com/d/forum/navitia
// www.navitia.io
use super::model::{self, BragiError};
use crate::query_settings::{BuildWeight, Proximity, QuerySettings, Types};
use geojson::Geometry;
use mimir::objects::{Addr, Admin, Coord, MimirObject, Poi, Stop, Street};
use mimir::rubber::{get_indexes, read_places, Rubber};
use prometheus::{self, exponential_buckets, histogram_opts, register_histogram_vec, HistogramVec};
use rs_es::error::EsError;
use rs_es::operations::search::{Source, Order};
use rs_es::query::compound::BoostMode;
use rs_es::query::functions::{DecayOptions, FilteredFunction, Function, Modifier};
use rs_es::query::Query;
use rs_es::units as rs_u;
use slog_scope::{debug, error, warn};
use std::{fmt, iter};

lazy_static::lazy_static! {
    static ref ES_REQ_HISTOGRAM: HistogramVec = register_histogram_vec!(
        "bragi_elasticsearch_request_duration_seconds",
        "The elasticsearch request latencies in seconds.",
        &["search_type"],
        exponential_buckets(0.001, 1.5, 25).unwrap()
    )
    .unwrap();
}

/// takes a ES json blob and build a Place from it
/// it uses the _type field of ES to know which type of the Place enum to fill
pub fn make_place(doc_type: String, value: Option<Box<serde_json::Value>>) -> Option<mimir::Place> {
    value.and_then(|v| {
        fn convert<T>(v: serde_json::Value, f: fn(T) -> mimir::Place) -> Option<mimir::Place>
        where
            for<'de> T: serde::Deserialize<'de>,
        {
            serde_json::from_value::<T>(v)
                .map_err(|err| warn!("Impossible to load ES result: {}", err))
                .ok()
                .map(f)
        }
        match doc_type.as_ref() {
            "addr" => convert(*v, mimir::Place::Addr),
            "street" => convert(*v, mimir::Place::Street),
            "admin" => convert(*v, mimir::Place::Admin),
            "poi" => convert(*v, mimir::Place::Poi),
            "stop" => convert(*v, mimir::Place::Stop),
            _ => {
                warn!("unknown ES return value, _type field = {}", doc_type);
                None
            }
        }
    })
}

#[derive(Debug, Eq, PartialEq)]
enum MatchType {
    Prefix,
    Fuzzy,
}

impl fmt::Display for MatchType {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        let printable = match *self {
            MatchType::Prefix => "prefix",
            MatchType::Fuzzy => "fuzzy",
        };
        write!(f, "{}", printable)
    }
}

// filter to handle PT coverages
// we either want:
// * to get objects with no coverage at all (non-PT objects)
// * or the objects with coverage matching the ones we're allowed to get
fn build_coverage_condition(pt_datasets: &[&str]) -> Query {
    Query::build_bool()
        .with_should(vec![
            Query::build_bool()
                .with_must_not(Query::build_exists("coverages").build())
                .build(),
            Query::build_terms("coverages")
                .with_values(pt_datasets)
                .build(),
        ])
        .build()
}

/// Create a `rs_es::Query` that boosts results according to the
/// distance to `coord`.
fn build_proximity_with_boost(coord: &Coord, infos: &Proximity, is_fuzzy: bool) -> Query {
    Query::build_function_score()
        .with_functions(vec![
            FilteredFunction::build_filtered_function(
                None,
                DecayOptions::new(
                    rs_u::Location::LatLon(coord.lat(), coord.lon()),
                    rs_u::Distance::new(infos.decay_distance, rs_u::DistanceUnit::Kilometer),
                )
                .with_offset(rs_u::Distance::new(
                    infos.offset_distance,
                    rs_u::DistanceUnit::Kilometer,
                ))
                .with_decay(infos.decay)
                .build("coord")
                .build_exp(),
                None,
            ),
            FilteredFunction::build_filtered_function(
                None,
                Function::build_weight(if is_fuzzy {
                    infos.weight_fuzzy
                } else {
                    infos.weight
                })
                .build(),
                None,
            ),
        ])
        .with_boost_mode(BoostMode::Replace)
        .build()
}

fn build_with_weight(build_weight: &BuildWeight, types: &Types) -> Query {
    let weighted = |doc_type, weight| {
        FilteredFunction::build_filtered_function(
            Query::build_term("_type", doc_type).build(),
            Function::build_field_value_factor("weight")
                .with_factor(build_weight.factor)
                .with_missing(build_weight.missing)
                .build(),
            Function::build_weight(weight),
        )
    };

    Query::build_function_score()
        .with_functions(vec![
            weighted(Stop::doc_type(), types.stop),
            weighted(Addr::doc_type(), types.address),
            weighted(Admin::doc_type(), types.admin),
            weighted(Poi::doc_type(), types.poi),
            weighted(Street::doc_type(), types.street),
        ])
        .with_boost_mode(BoostMode::Replace)
        .build()
}

#[allow(clippy::too_many_arguments)]
fn build_query<'a>(
    q: &str,
    match_type: MatchType,
    coord: Option<Coord>,
    shape: Option<Geometry>,
    pt_datasets: &[&str],
    all_data: bool,
    langs: &'a [&'a str],
    zone_types: &[&str],
    poi_types: &[&str],
    query_settings: &QuerySettings,
) -> Query {
    // Priorization by type
    fn match_type_with_boost<T: MimirObject>(boost: f64) -> Query {
        Query::build_term("_type", T::doc_type())
            .with_boost(boost)
            .build()
    }
    let type_query = Query::build_bool()
        .with_should(vec![
            match_type_with_boost::<Addr>(query_settings.type_query.boosts.address),
            match_type_with_boost::<Admin>(query_settings.type_query.boosts.admin),
            match_type_with_boost::<Stop>(query_settings.type_query.boosts.stop),
            match_type_with_boost::<Poi>(query_settings.type_query.boosts.poi),
            match_type_with_boost::<Street>(query_settings.type_query.boosts.street),
        ])
        .with_boost(query_settings.type_query.global)
        .build();

    let format_names_field = |lang| format!("names.{}", lang);
    let format_labels_field = |lang| format!("labels.{}", lang);
    let format_labels_prefix_field = |lang| format!("labels.{}.prefix", lang);

    let build_multi_match =
        |default_field: &str, lang_field_formatter: &dyn Fn(&'a &'a str) -> String| {
            let boosted_i18n_fields = langs.iter().map(lang_field_formatter);
            let fields: Vec<String> = iter::once(default_field.into())
                .chain(boosted_i18n_fields)
                .collect();
            Query::build_multi_match(fields, q)
        };

    // Priorization by query string
    let mut string_should = vec![
        build_multi_match("name", &format_names_field)
            .with_boost(query_settings.string_query.boosts.name)
            .build(),
        build_multi_match("label", &format_labels_field)
            .with_boost(query_settings.string_query.boosts.label)
            .build(),
        build_multi_match("label.prefix", &format_labels_prefix_field)
            .with_boost(query_settings.string_query.boosts.label_prefix)
            .build(),
        Query::build_match("zip_codes", q)
            .with_boost(query_settings.string_query.boosts.zip_codes)
            .build(),
        Query::build_match("house_number", q)
            .with_boost(query_settings.string_query.boosts.house_number)
            .build(),
    ];
    if let MatchType::Fuzzy = match_type {
        let format_labels_ngram_field = |lang| format!("labels.{}.ngram", lang);
        string_should.push(if coord.is_some() {
            build_multi_match("label.ngram", &format_labels_ngram_field)
                .with_boost(query_settings.string_query.boosts.label_ngram_with_coord)
                .build()
        } else {
            build_multi_match("label.ngram", &format_labels_ngram_field)
                .with_boost(query_settings.string_query.boosts.label_ngram)
                .build()
        });
    }
    let string_query = Query::build_bool()
        .with_should(string_should)
        .with_boost(query_settings.string_query.global)
        .build();

    let mut admin_weight = query_settings.importance_query.weights.coords_fuzzy.admin;

    // Priorization by importance
    let mut importance_queries = if let Some(ref coord) = coord {
        if let MatchType::Fuzzy = match_type {
            vec![
                build_with_weight(
                    &query_settings.importance_query.weights.coords_fuzzy,
                    &query_settings.importance_query.weights.types,
                ),
                build_proximity_with_boost(coord, &query_settings.importance_query.proximity, true),
            ]
        } else {
            admin_weight = query_settings.importance_query.weights.coords.admin;
            vec![
                build_with_weight(
                    &query_settings.importance_query.weights.coords,
                    &query_settings.importance_query.weights.types,
                ),
                build_proximity_with_boost(
                    coord,
                    &query_settings.importance_query.proximity,
                    false,
                ),
            ]
        }
    } else {
        admin_weight = query_settings.importance_query.weights.no_coords.admin;
        vec![build_with_weight(
            &query_settings.importance_query.weights.no_coords,
            &query_settings.importance_query.weights.types,
        )]
    };

    match match_type {
        MatchType::Prefix => {
            let admin_importance_query = Query::build_function_score()
                .with_query(Query::build_term("_type", Admin::doc_type()).build())
                .with_functions(vec![
                    FilteredFunction::build_filtered_function(
                        None,
                        Function::build_field_value_factor("weight")
                            .with_factor(1e6)
                            .with_modifier(Modifier::Log1p)
                            .with_missing(0.)
                            .build(),
                        None,
                    ),
                    FilteredFunction::build_filtered_function(
                        None,
                        Function::build_weight(admin_weight).build(),
                        None,
                    ),
                ])
                .with_boost_mode(BoostMode::Replace)
                .build();
            importance_queries.push(admin_importance_query);
        }
        MatchType::Fuzzy => {}
    };

    let house_number_condition = {
        if q.split_whitespace().count() > 1 {
            // Filter to handle house number.
            // We either want:
            // * to exactly match the document house_number
            // * or that the document has no house_number
            Query::build_bool()
                .with_should(vec![
                    Query::build_bool()
                        .with_must_not(Query::build_exists("house_number").build())
                        .build(),
                    Query::build_match("house_number", q.to_string()).build(),
                ])
                .build()
        } else {
            // If the query contains a single word, we don't exect any house number in the result.
            Query::build_bool()
                .with_must_not(Query::build_exists("house_number").build())
                .build()
        }
    };

    use rs_es::query::CombinationMinimumShouldMatch;
    use rs_es::query::MinimumShouldMatch;

    let matching_condition = match match_type {
        // When the match type is Prefix, we want to use every possible information even though
        // these are not present in label, for instance, the zip_code.
        // The field full_label contains all of them and will do the trick.
        MatchType::Prefix => Query::build_match("full_label.prefix".to_string(), q.to_string())
            .with_operator("and")
            .build(),
        // for fuzzy search we lower our expectation & we accept a certain percentage of token match
        // on full_label.ngram
        // The values defined here are empirical,
        // it's supposed to be able to manage cases BOTH missspelt one-word
        // www.elastic.co/guide/en/elasticsearch/guide/current/match-multi-word.html#match-precision
        // requests AND very long requests.
        // Missspelt one-word request:
        //     Vaureaaal (instead of Vaureal)
        // Very long requests:
        //     Caisse Primaire d'Assurance Maladie de Haute Garonne, 33 Rue du Lot, 31100 Toulouse
        MatchType::Fuzzy => Query::build_match("full_label.ngram".to_string(), q.to_string())
            .with_minimum_should_match(MinimumShouldMatch::from(vec![
                CombinationMinimumShouldMatch::new(1i64, -1i64),
                CombinationMinimumShouldMatch::new(3i64, -2i64),
                CombinationMinimumShouldMatch::new(9i64, -4i64),
                CombinationMinimumShouldMatch::new(20i64, 25f64),
            ]))
            .build(),
    };

    let mut filters = vec![house_number_condition, matching_condition];

    // if searching through all data, no coverage filter
    if !all_data {
        filters.push(build_coverage_condition(pt_datasets));
    }

    // We want to limit the search to the geographic shape given in argument,
    // except for stop areas
    if let Some(s) = shape {
        let filter_wo_stop = Query::build_bool()
            .with_must(vec![
                Query::build_bool()
                    .with_must_not(Query::build_term("_type", Stop::doc_type()).build())
                    .build(),
                Query::build_geo_shape("approx_coord")
                    .with_geojson(s)
                    .build(),
            ])
            .build();
        let filter_w_stop = Query::build_term("_type", Stop::doc_type()).build();
        let geo_filter = Query::build_bool()
            .with_should(vec![filter_w_stop, filter_wo_stop])
            .build();
        filters.push(geo_filter);
    }

    let mut query = Query::build_bool()
        .with_must(vec![type_query, string_query])
        .with_should(importance_queries)
        .with_filter(Query::build_bool().with_must(filters).build());

    if !zone_types.is_empty() {
        query = query.with_filter(
            Query::build_bool()
                .with_should(
                    zone_types
                        .iter()
                        .map(|x| Query::build_match("zone_type", *x).build())
                        .collect::<Vec<_>>(),
                )
                .build(),
        );
    }
    if !poi_types.is_empty() {
        query = query.with_filter(
            Query::build_bool()
                .with_should(
                    poi_types
                        .iter()
                        .map(|x| Query::build_match("poi_type.id", *x).build())
                        .collect::<Vec<_>>(),
                )
                .build(),
        );
    }

    query.build()
}

fn build_filter<'a>(
    coord: Option<Coord>,
    shape: Option<Geometry>,
    pt_datasets: &[&str],
    all_data: bool,
    zone_types: &[&str],
    poi_types: &[&str],
) -> Query {
    let mut filters = vec![];

    // if searching through all data, no coverage filter
    if !all_data {
        filters.push(build_coverage_condition(pt_datasets));
    }

    // We want to limit the search to the geographic shape given in argument,
    // except for stop areas
    if let Some(s) = shape {
        let filter_wo_stop = Query::build_bool()
            .with_must(vec![
                Query::build_bool()
                    .with_must_not(Query::build_term("_type", Stop::doc_type()).build())
                    .build(),
                Query::build_geo_shape("approx_coord")
                    .with_geojson(s)
                    .build(),
            ])
            .build();
        let filter_w_stop = Query::build_term("_type", Stop::doc_type()).build();
        let geo_filter = Query::build_bool()
            .with_should(vec![filter_w_stop, filter_wo_stop])
            .build();
        filters.push(geo_filter);
    }

    if !zone_types.is_empty() {
        let zone_types_filter = Query::build_bool()
            .with_should(
                zone_types
                .iter()
                .map(|x| Query::build_match("zone_type", *x).build())
                .collect::<Vec<_>>(),
            )
            .build();
        filters.push(zone_types_filter);
    }
    if !poi_types.is_empty() {
        let poi_types_filter = Query::build_bool()
            .with_should(
                poi_types
                .iter()
                .map(|x| Query::build_match("poi_type.id", *x).build())
                .collect::<Vec<_>>(),
            )
            .build();
        filters.push(poi_types_filter);
    }

    Query::build_bool()
        .with_must(Query::build_match_all().build())
        .with_filter(Query::build_bool().with_must(filters).build())
        .build()
}

#[allow(clippy::too_many_arguments)]
fn query(
    q: &str,
    pt_datasets: &[&str],
    poi_datasets: &[&str],
    all_data: bool,
    rubber: &mut Rubber,
    match_type: MatchType,
    offset: u64,
    limit: u64,
    coord: Option<Coord>,
    shape: Option<Geometry>,
    types: &[&str],
    zone_types: &[&str],
    poi_types: &[&str],
    langs: &[&str],
    debug: bool,
    query_settings: &QuerySettings,
) -> Result<Vec<mimir::Place>, EsError> {
    let query_type = match_type.to_string();
    let query = build_query(
        q,
        match_type,
        coord,
        shape,
        pt_datasets,
        all_data,
        langs,
        zone_types,
        poi_types,
        query_settings,
    );

    let indexes = get_indexes(all_data, &pt_datasets, &poi_datasets, types);
    let indexes = indexes
        .iter()
        .map(|index| index.as_str())
        .collect::<Vec<&str>>();
    debug!("ES indexes: {:?}", indexes);

    if indexes.is_empty() {
        // if there is no indexes, rs_es search with index "_all"
        // but we want to return empty response in this case.
        return Ok(vec![]);
    }
    let timer = ES_REQ_HISTOGRAM
        .get_metric_with_label_values(&[query_type.as_str()])
        .map(|h| h.start_timer())
        .map_err(
            |err| error!("impossible to get ES_REQ_HISTOGRAM metrics"; "err" => err.to_string()),
        )
        .ok();

    let timeout = rubber.timeout.map(|t| format!("{:?}", t));
    let mut search_query = rubber.es_client.search_query();

    let search_query = search_query
        .with_ignore_unavailable(true)
        .with_indexes(&indexes)
        .with_query(&query)
        .with_from(offset)
        .with_size(limit)
        // No need to fetch "boundary" as it's not used in the geocoding response
        // and is very large in some documents (countries...)
        .with_source(Source::exclude(&["boundary"]));

    // We don't want to clutter the Query URL, so we only add an explanation if the option is used
    let search_query = if debug {
        search_query.with_explain(true)
    } else {
        search_query
    };

    if let Some(timeout) = &timeout {
        search_query.with_timeout(timeout.as_str());
    }
    let result = search_query.send()?;

    if let Some(t) = timer {
        t.observe_duration();
    }

    read_places(result, coord.as_ref())
}

#[allow(clippy::too_many_arguments)]
fn filter(
    coord: Option<Coord>,
    pt_datasets: &[&str],
    poi_datasets: &[&str],
    all_data: bool,
    rubber: &mut Rubber,
    offset: u64,
    limit: u64,
    shape: Option<Geometry>,
    types: &[&str],
    zone_types: &[&str],
    poi_types: &[&str],
    debug: bool,
) -> Result<Vec<mimir::Place>, EsError> {
    let query = build_filter(
        coord,
        shape,
        pt_datasets,
        all_data,
        zone_types,
        poi_types
    );

    let indexes = get_indexes(all_data, &pt_datasets, &poi_datasets, types);
    let indexes = indexes
        .iter()
        .map(|index| index.as_str())
        .collect::<Vec<&str>>();
    debug!("ES indexes: {:?}", indexes);

    if indexes.is_empty() {
        // if there is no indexes, rs_es search with index "_all"
        // but we want to return empty response in this case.
        return Ok(vec![]);
    }
    let timer = ES_REQ_HISTOGRAM
        .get_metric_with_label_values(&["filter"])
        .map(|h| h.start_timer())
        .map_err(
            |err| error!("impossible to get ES_REQ_HISTOGRAM metrics"; "err" => err.to_string()),
        )
        .ok();

    let timeout = rubber.timeout.map(|t| format!("{:?}", t));
    let mut search_query = rubber.es_client.search_query();

    let mut sort_fields = vec![];

    if let Some(coord) = coord {
        // TODO: Coord should have an into<Location> trait instead.
        let location = rs_u::Location::LatLon(coord.y, coord.x);
        let geo_distance_sort = rs_es::operations::search::GeoDistance::new("coord")
            .with_location(location)
            .with_order(Order::Asc)
            .with_unit(rs_u::DistanceUnit::Meter)
            .build();

        sort_fields.push(geo_distance_sort);
    }
    let sort = rs_es::operations::search::Sort::new(sort_fields);

    let search_query = search_query
        .with_ignore_unavailable(true)
        .with_indexes(&indexes)
        .with_query(&query)
        .with_from(offset)
        .with_size(limit)
        .with_sort(&sort)
        // No need to fetch "boundary" as it's not used in the geocoding response
        // and is very large in some documents (countries...)
        .with_source(Source::exclude(&["boundary"]));

    // We don't want to clutter the Query URL, so we only add an explanation if the option is used
    let search_query = if debug {
        search_query.with_explain(true)
    } else {
        search_query
    };

    if let Some(timeout) = &timeout {
        search_query.with_timeout(timeout.as_str());
    }
    let result = search_query.send()?;

    if let Some(t) = timer {
        t.observe_duration();
    }

    read_places(result, coord.as_ref())
}

pub fn feature(
    pt_datasets: &[&str],
    poi_datasets: &[&str],
    all_data: bool,
    id: &str,
    mut rubber: Rubber,
) -> Result<Vec<mimir::Place>, BragiError> {
    let val = rs_es::units::JsonVal::String(id.into());
    let mut filters = vec![Query::build_ids(vec![val]).build()];

    // if searching through all data, no coverage filter
    if !all_data {
        filters.push(build_coverage_condition(pt_datasets));
    }
    let filter = Query::build_bool().with_must(filters).build();
    let query = Query::build_bool().with_filter(filter).build();

    let indexes = get_indexes(all_data, &pt_datasets, &poi_datasets, &[]);
    let indexes = indexes
        .iter()
        .map(|index| index.as_str())
        .collect::<Vec<&str>>();

    debug!("ES indexes: {:?}", indexes);

    if indexes.is_empty() {
        // if there is no indexes, rs_es search with index "_all"
        // but we want to return an error in this case.
        return Err(BragiError::ObjectNotFound);
    }

    let timer = ES_REQ_HISTOGRAM
        .get_metric_with_label_values(&["feature"])
        .map(|h| h.start_timer())
        .map_err(
            |err| error!("impossible to get ES_REQ_HISTOGRAM metrics"; "err" => err.to_string()),
        )
        .ok();

    let timeout = rubber.timeout.map(|t| format!("{:?}", t));
    let mut search_query = rubber.es_client.search_query();

    let search_query = search_query
        .with_ignore_unavailable(true)
        .with_indexes(&indexes)
        .with_query(&query);

    if let Some(timeout) = &timeout {
        search_query.with_timeout(timeout.as_str());
    }

    let result = search_query.send()?;

    if let Some(t) = timer {
        t.observe_duration()
    }

    if result.hits.total == 0 {
        Err(BragiError::ObjectNotFound)
    } else {
        read_places(result, None).map_err(model::BragiError::from)
    }
}

#[allow(clippy::too_many_arguments)]
pub fn features(
    pt_datasets: &[&str],
    poi_datasets: &[&str],
    all_data: bool,
    offset: u64,
    limit: u64,
    coord: Option<Coord>,
    shape: Option<Geometry>,
    types: &[&str],
    zone_types: &[&str],
    poi_types: &[&str],
    mut rubber: Rubber,
    debug: bool,
) -> Result<Vec<mimir::Place>, BragiError> {
    // Perform parameters validation.
    if !zone_types.is_empty() && !types.iter().any(|s| *s == "zone") {
        return Err(BragiError::InvalidParam(
            "zone_type[] parameter requires to have 'type[]=zone'",
        ));
    }
    if !poi_types.is_empty() && !types.iter().any(|s| *s == "poi") {
        return Err(BragiError::InvalidParam(
            "poi_type[] parameter requires to have 'type[]=poi'",
        ));
    }

    // First we try a pretty exact match on the prefix.
    // If there are no results then we do a new fuzzy search (matching ngrams)
    let results = filter(
        coord,
        &pt_datasets,
        &poi_datasets,
        all_data,
        &mut rubber,
        offset,
        limit,
        shape.clone(),
        &types,
        &zone_types,
        &poi_types,
        debug,
    )
    .map_err(model::BragiError::from)?;
    Ok(results)
}

#[allow(clippy::too_many_arguments)]
pub fn autocomplete(
    q: &str,
    pt_datasets: &[&str],
    poi_datasets: &[&str],
    all_data: bool,
    offset: u64,
    limit: u64,
    coord: Option<Coord>,
    shape: Option<Geometry>,
    types: &[&str],
    zone_types: &[&str],
    poi_types: &[&str],
    langs: &[&str],
    mut rubber: Rubber,
    debug: bool,
    query_settings: &QuerySettings,
) -> Result<Vec<mimir::Place>, BragiError> {
    // Perform parameters validation.
    if !zone_types.is_empty() && !types.iter().any(|s| *s == "zone") {
        return Err(BragiError::InvalidParam(
            "zone_type[] parameter requires to have 'type[]=zone'",
        ));
    }
    if !poi_types.is_empty() && !types.iter().any(|s| *s == "poi") {
        return Err(BragiError::InvalidParam(
            "poi_type[] parameter requires to have 'type[]=poi'",
        ));
    }

    // First we try a pretty exact match on the prefix.
    // If there are no results then we do a new fuzzy search (matching ngrams)
    let results = query(
        &q,
        &pt_datasets,
        &poi_datasets,
        all_data,
        &mut rubber,
        MatchType::Prefix,
        offset,
        limit,
        coord,
        shape.clone(),
        &types,
        &zone_types,
        &poi_types,
        &langs,
        debug,
        query_settings,
    )
    .map_err(model::BragiError::from)?;
    if results.is_empty() {
        query(
            &q,
            &pt_datasets,
            &poi_datasets,
            all_data,
            &mut rubber,
            MatchType::Fuzzy,
            offset,
            limit,
            coord,
            shape,
            &types,
            &zone_types,
            &poi_types,
            &langs,
            debug,
            query_settings,
        )
        .map_err(model::BragiError::from)
    } else {
        Ok(results)
    }
}
